{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.lines as mlines\n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing \n",
    "from sklearn import datasets, linear_model\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#will use min max scaler\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import KFold \n",
    "#from sklearn.metrics import mean_squared_error\n",
    "#from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the dataset\n",
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['sentiment','id','date',\n",
    "                     'query_type','user','tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query_type</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date query_type  \\\n",
       "0          0  1467810672  Mon Apr 06 22:19:49 PDT 2009   NO_QUERY   \n",
       "1          0  1467810917  Mon Apr 06 22:19:53 PDT 2009   NO_QUERY   \n",
       "2          0  1467811184  Mon Apr 06 22:19:57 PDT 2009   NO_QUERY   \n",
       "3          0  1467811193  Mon Apr 06 22:19:57 PDT 2009   NO_QUERY   \n",
       "4          0  1467811372  Mon Apr 06 22:20:00 PDT 2009   NO_QUERY   \n",
       "\n",
       "            user                                              tweet  \n",
       "0  scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "1       mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "2        ElleCTF    my whole body feels itchy and like its on fire   \n",
       "3         Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "4       joy_wolf                      @Kwesidei not the whole crew   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query_type</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1599994</td>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599995</td>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599996</td>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599997</td>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599998</td>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment          id                          date query_type  \\\n",
       "1599994          4  2193601966  Tue Jun 16 08:40:49 PDT 2009   NO_QUERY   \n",
       "1599995          4  2193601969  Tue Jun 16 08:40:49 PDT 2009   NO_QUERY   \n",
       "1599996          4  2193601991  Tue Jun 16 08:40:49 PDT 2009   NO_QUERY   \n",
       "1599997          4  2193602064  Tue Jun 16 08:40:49 PDT 2009   NO_QUERY   \n",
       "1599998          4  2193602129  Tue Jun 16 08:40:50 PDT 2009   NO_QUERY   \n",
       "\n",
       "                    user                                              tweet  \n",
       "1599994  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599995      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599996           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599997     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599998   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599999 entries, 0 to 1599998\n",
      "Data columns (total 6 columns):\n",
      "sentiment     1599999 non-null int64\n",
      "id            1599999 non-null int64\n",
      "date          1599999 non-null object\n",
      "query_type    1599999 non-null object\n",
      "user          1599999 non-null object\n",
      "tweet         1599999 non-null object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment     0\n",
       "id            0\n",
       "date          0\n",
       "query_type    0\n",
       "user          0\n",
       "tweet         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    799999\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['date','query_type','user'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811592</td>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811594</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811795</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1467812025</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1467812416</td>\n",
       "      <td>spring break in plain city... it's snowing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                                              tweet\n",
       "0          0  1467810672  is upset that he can't update his Facebook by ...\n",
       "1          0  1467810917  @Kenichan I dived many times for the ball. Man...\n",
       "2          0  1467811184    my whole body feels itchy and like its on fire \n",
       "3          0  1467811193  @nationwideclass no, it's not behaving at all....\n",
       "4          0  1467811372                      @Kwesidei not the whole crew \n",
       "5          0  1467811592                                        Need a hug \n",
       "6          0  1467811594  @LOLTrish hey  long time no see! Yes.. Rains a...\n",
       "7          0  1467811795               @Tatiana_K nope they didn't have it \n",
       "8          0  1467812025                          @twittera que me muera ? \n",
       "9          0  1467812416        spring break in plain city... it's snowing "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>799999</td>\n",
       "      <td>4</td>\n",
       "      <td>1467822272</td>\n",
       "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800000</td>\n",
       "      <td>4</td>\n",
       "      <td>1467822273</td>\n",
       "      <td>im meeting up with one of my besties tonight! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800001</td>\n",
       "      <td>4</td>\n",
       "      <td>1467822283</td>\n",
       "      <td>@DaRealSunisaKim Thanks for the Twitter add, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800002</td>\n",
       "      <td>4</td>\n",
       "      <td>1467822287</td>\n",
       "      <td>Being sick can be really cheap when it hurts t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800003</td>\n",
       "      <td>4</td>\n",
       "      <td>1467822293</td>\n",
       "      <td>@LovesBrooklyn2 he has that effect on everyone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800004</td>\n",
       "      <td>4</td>\n",
       "      <td>1467822391</td>\n",
       "      <td>@ProductOfFear You can tell him that I just bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800005</td>\n",
       "      <td>4</td>\n",
       "      <td>1467822447</td>\n",
       "      <td>@r_keith_hill Thans for your response. Ihad al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800006</td>\n",
       "      <td>4</td>\n",
       "      <td>1467822465</td>\n",
       "      <td>@KeepinUpWKris I am so jealous, hope you had a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800007</td>\n",
       "      <td>4</td>\n",
       "      <td>1467822489</td>\n",
       "      <td>@tommcfly ah, congrats mr fletcher for finally...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800008</td>\n",
       "      <td>4</td>\n",
       "      <td>1467822496</td>\n",
       "      <td>@e4VoIP I RESPONDED  Stupid cat is helping me ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment          id  \\\n",
       "799999          4  1467822272   \n",
       "800000          4  1467822273   \n",
       "800001          4  1467822283   \n",
       "800002          4  1467822287   \n",
       "800003          4  1467822293   \n",
       "800004          4  1467822391   \n",
       "800005          4  1467822447   \n",
       "800006          4  1467822465   \n",
       "800007          4  1467822489   \n",
       "800008          4  1467822496   \n",
       "\n",
       "                                                    tweet  \n",
       "799999       I LOVE @Health4UandPets u guys r the best!!   \n",
       "800000  im meeting up with one of my besties tonight! ...  \n",
       "800001  @DaRealSunisaKim Thanks for the Twitter add, S...  \n",
       "800002  Being sick can be really cheap when it hurts t...  \n",
       "800003    @LovesBrooklyn2 he has that effect on everyone   \n",
       "800004  @ProductOfFear You can tell him that I just bu...  \n",
       "800005  @r_keith_hill Thans for your response. Ihad al...  \n",
       "800006  @KeepinUpWKris I am so jealous, hope you had a...  \n",
       "800007  @tommcfly ah, congrats mr fletcher for finally...  \n",
       "800008  @e4VoIP I RESPONDED  Stupid cat is helping me ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.sentiment == 4].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = [len(t) for t in df.tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "plt.boxplot(df.length)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since Twitter Maximum Character Length is 280 so we remove the tweets beyondthat limit\n",
    "df.drop(df[df['length'] > 280].index, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: The unescape method is deprecated and will be removed in 3.5, use html.unescape() instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#Converting html entities\n",
    "from html.parser import HTMLParser\n",
    "html_parser = HTMLParser()\n",
    "# Created a new columns i.e. clean_tweet contains the same tweets but cleaned version\n",
    "df['clean_tweet'] = df['tweet'].apply(lambda x: html_parser.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>length</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>111</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>89</td>\n",
       "      <td>I dived many times for the ball. Managed to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>47</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>111</td>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>29</td>\n",
       "      <td>not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811592</td>\n",
       "      <td>Need a hug</td>\n",
       "      <td>11</td>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811594</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "      <td>99</td>\n",
       "      <td>hey  long time no see! Yes.. Rains a bit ,onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811795</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "      <td>36</td>\n",
       "      <td>nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1467812025</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "      <td>25</td>\n",
       "      <td>que me muera ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1467812416</td>\n",
       "      <td>spring break in plain city... it's snowing</td>\n",
       "      <td>43</td>\n",
       "      <td>spring break in plain city... it's snowing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                                              tweet  \\\n",
       "0          0  1467810672  is upset that he can't update his Facebook by ...   \n",
       "1          0  1467810917  @Kenichan I dived many times for the ball. Man...   \n",
       "2          0  1467811184    my whole body feels itchy and like its on fire    \n",
       "3          0  1467811193  @nationwideclass no, it's not behaving at all....   \n",
       "4          0  1467811372                      @Kwesidei not the whole crew    \n",
       "5          0  1467811592                                        Need a hug    \n",
       "6          0  1467811594  @LOLTrish hey  long time no see! Yes.. Rains a...   \n",
       "7          0  1467811795               @Tatiana_K nope they didn't have it    \n",
       "8          0  1467812025                          @twittera que me muera ?    \n",
       "9          0  1467812416        spring break in plain city... it's snowing    \n",
       "\n",
       "   length                                        clean_tweet  \n",
       "0     111  is upset that he can't update his Facebook by ...  \n",
       "1      89   I dived many times for the ball. Managed to s...  \n",
       "2      47    my whole body feels itchy and like its on fire   \n",
       "3     111   no, it's not behaving at all. i'm mad. why am...  \n",
       "4      29                                not the whole crew   \n",
       "5      11                                        Need a hug   \n",
       "6      99   hey  long time no see! Yes.. Rains a bit ,onl...  \n",
       "7      36                          nope they didn't have it   \n",
       "8      25                                    que me muera ?   \n",
       "9      43        spring break in plain city... it's snowing   "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "#Removing \"@user\" from all the tweets\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "    return input_txt\n",
    "# remove twitter handles (@user)\n",
    "df['clean_tweet'] = np.vectorize(remove_pattern)(df['clean_tweet'], \"@[\\w]*\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>length</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>111</td>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>89</td>\n",
       "      <td>i dived many times for the ball. managed to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>47</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>111</td>\n",
       "      <td>no, it's not behaving at all. i'm mad. why am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>29</td>\n",
       "      <td>not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811592</td>\n",
       "      <td>Need a hug</td>\n",
       "      <td>11</td>\n",
       "      <td>need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811594</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "      <td>99</td>\n",
       "      <td>hey  long time no see! yes.. rains a bit ,onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811795</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "      <td>36</td>\n",
       "      <td>nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1467812025</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "      <td>25</td>\n",
       "      <td>que me muera ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1467812416</td>\n",
       "      <td>spring break in plain city... it's snowing</td>\n",
       "      <td>43</td>\n",
       "      <td>spring break in plain city... it's snowing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                                              tweet  \\\n",
       "0          0  1467810672  is upset that he can't update his Facebook by ...   \n",
       "1          0  1467810917  @Kenichan I dived many times for the ball. Man...   \n",
       "2          0  1467811184    my whole body feels itchy and like its on fire    \n",
       "3          0  1467811193  @nationwideclass no, it's not behaving at all....   \n",
       "4          0  1467811372                      @Kwesidei not the whole crew    \n",
       "5          0  1467811592                                        Need a hug    \n",
       "6          0  1467811594  @LOLTrish hey  long time no see! Yes.. Rains a...   \n",
       "7          0  1467811795               @Tatiana_K nope they didn't have it    \n",
       "8          0  1467812025                          @twittera que me muera ?    \n",
       "9          0  1467812416        spring break in plain city... it's snowing    \n",
       "\n",
       "   length                                        clean_tweet  \n",
       "0     111  is upset that he can't update his facebook by ...  \n",
       "1      89   i dived many times for the ball. managed to s...  \n",
       "2      47    my whole body feels itchy and like its on fire   \n",
       "3     111   no, it's not behaving at all. i'm mad. why am...  \n",
       "4      29                                not the whole crew   \n",
       "5      11                                        need a hug   \n",
       "6      99   hey  long time no see! yes.. rains a bit ,onl...  \n",
       "7      36                          nope they didn't have it   \n",
       "8      25                                    que me muera ?   \n",
       "9      43        spring break in plain city... it's snowing   "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Changing all the tweets into lowercase\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: x.lower())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apostrophe Dictionary\n",
    "apostrophe_dict = {\n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is\",\n",
    "\"i'd\": \"I would\",\n",
    "\"i'd've\": \"I would have\",\n",
    "\"i'll\": \"I will\",\n",
    "\"i'll've\": \"I will have\",\n",
    "\"i'm\": \"I am\",\n",
    "\"i've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_dict(text, dictionary):\n",
    "    for word in text.split():\n",
    "        if word.lower() in dictionary:\n",
    "            if word.lower() in text.split():\n",
    "                text = text.replace(word, dictionary[word.lower()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: lookup_dict(x,apostrophe_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_word_dict = {\n",
    "\"121\": \"one to one\",\n",
    "\"a/s/l\": \"age, sex, location\",\n",
    "\"adn\": \"any day now\",\n",
    "\"afaik\": \"as far as I know\",\n",
    "\"afk\": \"away from keyboard\",\n",
    "\"aight\": \"alright\",\n",
    "\"alol\": \"actually laughing out loud\",\n",
    "\"b4\": \"before\",\n",
    "\"b4n\": \"bye for now\",\n",
    "\"bak\": \"back at the keyboard\",\n",
    "\"bf\": \"boyfriend\",\n",
    "\"bff\": \"best friends forever\",\n",
    "\"bfn\": \"bye for now\",\n",
    "\"bg\": \"big grin\",\n",
    "\"bta\": \"but then again\",\n",
    "\"btw\": \"by the way\",\n",
    "\"cid\": \"crying in disgrace\",\"cnp\": \"continued in my next post\",\n",
    "\"cp\": \"chat post\",\n",
    "\"cu\": \"see you\",\n",
    "\"cul\": \"see you later\",\n",
    "\"cul8r\": \"see you later\",\n",
    "\"cya\": \"bye\",\n",
    "\"cyo\": \"see you online\",\n",
    "\"dbau\": \"doing business as usual\",\n",
    "\"fud\": \"fear, uncertainty, and doubt\",\n",
    "\"fwiw\": \"for what it's worth\",\n",
    "\"fyi\": \"for your information\",\n",
    "\"g\": \"grin\",\n",
    "\"g2g\": \"got to go\",\n",
    "\"ga\": \"go ahead\",\n",
    "\"gal\": \"get a life\",\n",
    "\"gf\": \"girlfriend\",\"gfn\": \"gone for now\",\n",
    "\"gmbo\": \"giggling my butt off\",\n",
    "\"gmta\": \"great minds think alike\",\n",
    "\"h8\": \"hate\",\n",
    "\"hagn\": \"have a good night\",\n",
    "\"hdop\": \"help delete online predators\",\n",
    "\"hhis\": \"hanging head in shame\",\n",
    "\"iac\": \"in any case\",\n",
    "\"ianal\": \"I am not a lawyer\",\n",
    "\"ic\": \"I see\",\n",
    "\"idk\": \"I don't know\",\n",
    "\"imao\": \"in my arrogant opinion\",\n",
    "\"imnsho\": \"in my not so humble opinion\",\n",
    "\"imo\": \"in my opinion\",\n",
    "\"iow\": \"in other words\",\n",
    "\"ipn\": \"Iâ€™m posting naked\",\"irl\": \"in real life\",\n",
    "\"jk\": \"just kidding\",\n",
    "\"l8r\": \"later\",\n",
    "\"ld\": \"later, dude\",\n",
    "\"ldr\": \"long distance relationship\",\n",
    "\"llta\": \"lots and lots of thunderous applause\",\n",
    "\"lmao\": \"laugh my ass off\",\n",
    "\"lmirl\": \"let's meet in real life\",\n",
    "\"lol\": \"laugh out loud\",\n",
    "\"ltr\": \"longterm relationship\",\n",
    "\"lulab\": \"love you like a brother\",\n",
    "\"lulas\": \"love you like a sister\",\n",
    "\"luv\": \"love\",\n",
    "\"m/f\": \"male or female\",\"m8\": \"mate\",\n",
    "\"milf\": \"mother I would like to fuck\",\n",
    "\"oll\": \"online love\",\n",
    "\"omg\": \"oh my god\",\n",
    "\"otoh\": \"on the other hand\",\n",
    "\"pir\": \"parent in room\",\n",
    "\"ppl\": \"people\",\n",
    "\"r\": \"are\",\n",
    "\"rofl\": \"roll on the floor laughing\",\n",
    "\"rpg\": \"role playing games\",\n",
    "\"ru\": \"are you\",\n",
    "\"shid\": \"slaps head in disgust\",\n",
    "\"somy\": \"sick of me yet\",\n",
    "\"sot\": \"short of time\",\n",
    "\"thanx\": \"thanks\",\n",
    "\"thx\": \"thanks\",\n",
    "\"ttyl\": \"talk to you later\",\n",
    "\"u\": \"you\",\n",
    "\"ur\": \"you are\",\n",
    "\"uw\": \"youâ€™re welcome\",\n",
    "\"wb\": \"welcome back\",\n",
    "\"wfm\": \"works for me\",\n",
    "\"wibni\": \"wouldn't it be nice if\",\"wtf\": \"what the fuck\",\n",
    "\"wtg\": \"way to go\",\n",
    "\"wtgp\": \"want to go private\",\n",
    "\"ym\": \"young man\",\n",
    "\"gr8\": \"great\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: lookup_dict(x,short_word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticon_dict = {\n",
    "\":)\": \"happy\",\n",
    "\":â€‘)\": \"happy\",\n",
    "\":-]\": \"happy\",\n",
    "\":-3\": \"happy\",\n",
    "\":->\": \"happy\",\n",
    "\"8-)\": \"happy\",\n",
    "\":-}\": \"happy\",\n",
    "\":o)\": \"happy\",\n",
    "\":c)\": \"happy\",\n",
    "\":^)\": \"happy\",\n",
    "\"=]\": \"happy\",\n",
    "\"=)\": \"happy\",\n",
    "\"<3\": \"happy\",\n",
    "\":-(\": \"sad\",\n",
    "\":(\": \"sad\",\n",
    "\":c\": \"sad\",\":<\": \"sad\",\n",
    "\":[\": \"sad\",\n",
    "\">:[\": \"sad\",\n",
    "\":{\": \"sad\",\n",
    "\">:(\": \"sad\",\n",
    "\":-c\": \"sad\",\n",
    "\":-< \": \"sad\",\n",
    "\":-[\": \"sad\",\n",
    "\":-||\": \"sad\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: lookup_dict(x,emoticon_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing punctuations withspace\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: re.sub(r'[^\\w\\s]',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing special characters with space\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing numbers with space\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: re.sub(r'[^a-zA-Z]',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>length</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>111</td>\n",
       "      <td>is upset that he cannot update his facebook by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>89</td>\n",
       "      <td>i dived many times for the ball  managed to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>47</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>111</td>\n",
       "      <td>no  it is not behaving at all  I am mad  why ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>29</td>\n",
       "      <td>not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811592</td>\n",
       "      <td>Need a hug</td>\n",
       "      <td>11</td>\n",
       "      <td>need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811594</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "      <td>99</td>\n",
       "      <td>hey  long time no see  yes   rains a bit  onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811795</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "      <td>36</td>\n",
       "      <td>nope they did not have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1467812025</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "      <td>25</td>\n",
       "      <td>que me muera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1467812416</td>\n",
       "      <td>spring break in plain city... it's snowing</td>\n",
       "      <td>43</td>\n",
       "      <td>spring break in plain city    it is snowing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                                              tweet  \\\n",
       "0          0  1467810672  is upset that he can't update his Facebook by ...   \n",
       "1          0  1467810917  @Kenichan I dived many times for the ball. Man...   \n",
       "2          0  1467811184    my whole body feels itchy and like its on fire    \n",
       "3          0  1467811193  @nationwideclass no, it's not behaving at all....   \n",
       "4          0  1467811372                      @Kwesidei not the whole crew    \n",
       "5          0  1467811592                                        Need a hug    \n",
       "6          0  1467811594  @LOLTrish hey  long time no see! Yes.. Rains a...   \n",
       "7          0  1467811795               @Tatiana_K nope they didn't have it    \n",
       "8          0  1467812025                          @twittera que me muera ?    \n",
       "9          0  1467812416        spring break in plain city... it's snowing    \n",
       "\n",
       "   length                                        clean_tweet  \n",
       "0     111  is upset that he cannot update his facebook by...  \n",
       "1      89   i dived many times for the ball  managed to s...  \n",
       "2      47    my whole body feels itchy and like its on fire   \n",
       "3     111   no  it is not behaving at all  I am mad  why ...  \n",
       "4      29                                not the whole crew   \n",
       "5      11                                        need a hug   \n",
       "6      99   hey  long time no see  yes   rains a bit  onl...  \n",
       "7      36                         nope they did not have it   \n",
       "8      25                                    que me muera     \n",
       "9      43       spring break in plain city    it is snowing   "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from textblob import TextBlob\n",
    "# Not cleaning the just showing the spelling check as its take lot of time to process all these tweets\n",
    "## Shown sample how its must done\n",
    "df['clean_tweet'] = df['clean_tweet'][0:10].apply(lambda x: str(TextBlob(x).correct()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing stop words from NLTK coupus and word tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>length</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>111</td>\n",
       "      <td>is upset that he cannot update his facebook by...</td>\n",
       "      <td>[is, upset, that, he, can, not, update, his, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>89</td>\n",
       "      <td>i dived many times for the ball  managed to s...</td>\n",
       "      <td>[i, dived, many, times, for, the, ball, manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>47</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>111</td>\n",
       "      <td>no  it is not behaving at all  I am mad  why ...</td>\n",
       "      <td>[no, it, is, not, behaving, at, all, I, am, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>29</td>\n",
       "      <td>not the whole crew</td>\n",
       "      <td>[not, the, whole, crew]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811592</td>\n",
       "      <td>Need a hug</td>\n",
       "      <td>11</td>\n",
       "      <td>need a hug</td>\n",
       "      <td>[need, a, hug]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811594</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "      <td>99</td>\n",
       "      <td>hey  long time no see  yes   rains a bit  onl...</td>\n",
       "      <td>[hey, long, time, no, see, yes, rains, a, bit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811795</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "      <td>36</td>\n",
       "      <td>nope they did not have it</td>\n",
       "      <td>[nope, they, did, not, have, it]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1467812025</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "      <td>25</td>\n",
       "      <td>que me muera</td>\n",
       "      <td>[que, me, muera]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1467812416</td>\n",
       "      <td>spring break in plain city... it's snowing</td>\n",
       "      <td>43</td>\n",
       "      <td>spring break in plain city    it is snowing</td>\n",
       "      <td>[spring, break, in, plain, city, it, is, snowing]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                                              tweet  \\\n",
       "0          0  1467810672  is upset that he can't update his Facebook by ...   \n",
       "1          0  1467810917  @Kenichan I dived many times for the ball. Man...   \n",
       "2          0  1467811184    my whole body feels itchy and like its on fire    \n",
       "3          0  1467811193  @nationwideclass no, it's not behaving at all....   \n",
       "4          0  1467811372                      @Kwesidei not the whole crew    \n",
       "5          0  1467811592                                        Need a hug    \n",
       "6          0  1467811594  @LOLTrish hey  long time no see! Yes.. Rains a...   \n",
       "7          0  1467811795               @Tatiana_K nope they didn't have it    \n",
       "8          0  1467812025                          @twittera que me muera ?    \n",
       "9          0  1467812416        spring break in plain city... it's snowing    \n",
       "\n",
       "   length                                        clean_tweet  \\\n",
       "0     111  is upset that he cannot update his facebook by...   \n",
       "1      89   i dived many times for the ball  managed to s...   \n",
       "2      47    my whole body feels itchy and like its on fire    \n",
       "3     111   no  it is not behaving at all  I am mad  why ...   \n",
       "4      29                                not the whole crew    \n",
       "5      11                                        need a hug    \n",
       "6      99   hey  long time no see  yes   rains a bit  onl...   \n",
       "7      36                         nope they did not have it    \n",
       "8      25                                    que me muera      \n",
       "9      43       spring break in plain city    it is snowing    \n",
       "\n",
       "                                         tweet_token  \n",
       "0  [is, upset, that, he, can, not, update, his, f...  \n",
       "1  [i, dived, many, times, for, the, ball, manage...  \n",
       "2  [my, whole, body, feels, itchy, and, like, its...  \n",
       "3  [no, it, is, not, behaving, at, all, I, am, ma...  \n",
       "4                            [not, the, whole, crew]  \n",
       "5                                     [need, a, hug]  \n",
       "6  [hey, long, time, no, see, yes, rains, a, bit,...  \n",
       "7                   [nope, they, did, not, have, it]  \n",
       "8                                   [que, me, muera]  \n",
       "9  [spring, break, in, plain, city, it, is, snowing]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating token for the clean tweets\n",
    "df['tweet_token'] = df['clean_tweet'].apply(lambda x: word_tokenize(x))\n",
    "## Fully formated tweets & there tokens\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1599981 entries, 0 to 1599998\n",
      "Data columns (total 6 columns):\n",
      "sentiment      1599981 non-null int64\n",
      "id             1599981 non-null int64\n",
      "tweet          1599981 non-null object\n",
      "length         1599981 non-null int64\n",
      "clean_tweet    1599981 non-null object\n",
      "tweet_token    1599981 non-null object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 85.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing stop words from NLTK corpus for english language\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words# Importing stop words from NLTK corpus for english language\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[is, upset, that, he, can, not, update, his, f...</td>\n",
       "      <td>[upset, update, facebook, texting, might, cry,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[i, dived, many, times, for, the, ball, manage...</td>\n",
       "      <td>[dived, many, times, ball, managed, save, rest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[no, it, is, not, behaving, at, all, I, am, ma...</td>\n",
       "      <td>[behaving, I, mad, see]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[not, the, whole, crew]</td>\n",
       "      <td>[whole, crew]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>[so, rylee, grace, wana, go, steve, s, party, ...</td>\n",
       "      <td>[rylee, grace, wana, go, steve, party, sadly, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>[hey, i, actually, won, one, of, my, bracket, ...</td>\n",
       "      <td>[hey, actually, one, bracket, pools, bad, one,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>[you, do, not, follow, me, either, and, i, wor...</td>\n",
       "      <td>[follow, either, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>[a, bad, nite, for, the, favorite, teams, astr...</td>\n",
       "      <td>[bad, nite, favorite, teams, astros, spartans,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>[body, of, missing, northern, calif, girl, fou...</td>\n",
       "      <td>[body, missing, northern, calif, girl, found, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_token  \\\n",
       "0   [is, upset, that, he, can, not, update, his, f...   \n",
       "1   [i, dived, many, times, for, the, ball, manage...   \n",
       "2   [my, whole, body, feels, itchy, and, like, its...   \n",
       "3   [no, it, is, not, behaving, at, all, I, am, ma...   \n",
       "4                             [not, the, whole, crew]   \n",
       "..                                                ...   \n",
       "95  [so, rylee, grace, wana, go, steve, s, party, ...   \n",
       "96  [hey, i, actually, won, one, of, my, bracket, ...   \n",
       "97  [you, do, not, follow, me, either, and, i, wor...   \n",
       "98  [a, bad, nite, for, the, favorite, teams, astr...   \n",
       "99  [body, of, missing, northern, calif, girl, fou...   \n",
       "\n",
       "                                 tweet_token_filtered  \n",
       "0   [upset, update, facebook, texting, might, cry,...  \n",
       "1   [dived, many, times, ball, managed, save, rest...  \n",
       "2             [whole, body, feels, itchy, like, fire]  \n",
       "3                             [behaving, I, mad, see]  \n",
       "4                                       [whole, crew]  \n",
       "..                                                ...  \n",
       "95  [rylee, grace, wana, go, steve, party, sadly, ...  \n",
       "96  [hey, actually, one, bracket, pools, bad, one,...  \n",
       "97                             [follow, either, work]  \n",
       "98  [bad, nite, favorite, teams, astros, spartans,...  \n",
       "99  [body, missing, northern, calif, girl, found, ...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Created new columns of tokens - where stop words are being removed\n",
    "df['tweet_token_filtered'] = df['tweet_token'].apply(lambda x: [word for word in x if not word in stop_words])\n",
    "\n",
    "## Tokens columns with stop words and without stop words\n",
    "df[['tweet_token', 'tweet_token_filtered']].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[is, upset, that, he, can, not, update, his, f...</td>\n",
       "      <td>[upset, update, facebook, texting, might, cry,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[i, dived, many, times, for, the, ball, manage...</td>\n",
       "      <td>[dived, many, times, ball, managed, save, rest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[no, it, is, not, behaving, at, all, I, am, ma...</td>\n",
       "      <td>[behaving, I, mad, see]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[not, the, whole, crew]</td>\n",
       "      <td>[whole, crew]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>[so, rylee, grace, wana, go, steve, s, party, ...</td>\n",
       "      <td>[rylee, grace, wana, go, steve, party, sadly, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>[hey, i, actually, won, one, of, my, bracket, ...</td>\n",
       "      <td>[hey, actually, one, bracket, pools, bad, one,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>[you, do, not, follow, me, either, and, i, wor...</td>\n",
       "      <td>[follow, either, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>[a, bad, nite, for, the, favorite, teams, astr...</td>\n",
       "      <td>[bad, nite, favorite, teams, astros, spartans,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>[body, of, missing, northern, calif, girl, fou...</td>\n",
       "      <td>[body, missing, northern, calif, girl, found, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_token  \\\n",
       "0   [is, upset, that, he, can, not, update, his, f...   \n",
       "1   [i, dived, many, times, for, the, ball, manage...   \n",
       "2   [my, whole, body, feels, itchy, and, like, its...   \n",
       "3   [no, it, is, not, behaving, at, all, I, am, ma...   \n",
       "4                             [not, the, whole, crew]   \n",
       "..                                                ...   \n",
       "95  [so, rylee, grace, wana, go, steve, s, party, ...   \n",
       "96  [hey, i, actually, won, one, of, my, bracket, ...   \n",
       "97  [you, do, not, follow, me, either, and, i, wor...   \n",
       "98  [a, bad, nite, for, the, favorite, teams, astr...   \n",
       "99  [body, of, missing, northern, calif, girl, fou...   \n",
       "\n",
       "                                 tweet_token_filtered  \n",
       "0   [upset, update, facebook, texting, might, cry,...  \n",
       "1   [dived, many, times, ball, managed, save, rest...  \n",
       "2             [whole, body, feels, itchy, like, fire]  \n",
       "3                             [behaving, I, mad, see]  \n",
       "4                                       [whole, crew]  \n",
       "..                                                ...  \n",
       "95  [rylee, grace, wana, go, steve, party, sadly, ...  \n",
       "96  [hey, actually, one, bracket, pools, bad, one,...  \n",
       "97                             [follow, either, work]  \n",
       "98  [bad, nite, favorite, teams, astros, spartans,...  \n",
       "99  [body, missing, northern, calif, girl, found, ...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# Created new columns of tokens - where stop words are being removed\n",
    "df['tweet_token_filtered'] = df['tweet_token'].apply(lambda x: [word for word in x if not word in stop_words])\n",
    "\n",
    "## Tokens columns with stop words and without stop words\n",
    "df[['tweet_token', 'tweet_token_filtered']].head(10)# Created new columns of tokens - where stop words are being removed\n",
    "df['tweet_token_filtered'] = df['tweet_token'].apply(lambda x: [word for word in x if not word in stop_words])\n",
    "\n",
    "## Tokens columns with stop words and without stop words\n",
    "df[['tweet_token', 'tweet_token_filtered']].head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>length</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>111</td>\n",
       "      <td>is upset that he cannot update his facebook by...</td>\n",
       "      <td>[is, upset, that, he, can, not, update, his, f...</td>\n",
       "      <td>[upset, update, facebook, texting, might, cry,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>89</td>\n",
       "      <td>i dived many times for the ball  managed to s...</td>\n",
       "      <td>[i, dived, many, times, for, the, ball, manage...</td>\n",
       "      <td>[dived, many, times, ball, managed, save, rest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>47</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>111</td>\n",
       "      <td>no  it is not behaving at all  I am mad  why ...</td>\n",
       "      <td>[no, it, is, not, behaving, at, all, I, am, ma...</td>\n",
       "      <td>[behaving, I, mad, see]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>29</td>\n",
       "      <td>not the whole crew</td>\n",
       "      <td>[not, the, whole, crew]</td>\n",
       "      <td>[whole, crew]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                                              tweet  \\\n",
       "0          0  1467810672  is upset that he can't update his Facebook by ...   \n",
       "1          0  1467810917  @Kenichan I dived many times for the ball. Man...   \n",
       "2          0  1467811184    my whole body feels itchy and like its on fire    \n",
       "3          0  1467811193  @nationwideclass no, it's not behaving at all....   \n",
       "4          0  1467811372                      @Kwesidei not the whole crew    \n",
       "\n",
       "   length                                        clean_tweet  \\\n",
       "0     111  is upset that he cannot update his facebook by...   \n",
       "1      89   i dived many times for the ball  managed to s...   \n",
       "2      47    my whole body feels itchy and like its on fire    \n",
       "3     111   no  it is not behaving at all  I am mad  why ...   \n",
       "4      29                                not the whole crew    \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [is, upset, that, he, can, not, update, his, f...   \n",
       "1  [i, dived, many, times, for, the, ball, manage...   \n",
       "2  [my, whole, body, feels, itchy, and, like, its...   \n",
       "3  [no, it, is, not, behaving, at, all, I, am, ma...   \n",
       "4                            [not, the, whole, crew]   \n",
       "\n",
       "                                tweet_token_filtered  \n",
       "0  [upset, update, facebook, texting, might, cry,...  \n",
       "1  [dived, many, times, ball, managed, save, rest...  \n",
       "2            [whole, body, feels, itchy, like, fire]  \n",
       "3                            [behaving, I, mad, see]  \n",
       "4                                      [whole, crew]  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizing = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\KIIT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_lemmatized'] = df['tweet_token_filtered'].apply(lambda x: ' '.join([lemmatizing.lemmatize(i) for i in x]))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm = vectorizer.fit_transform(df['tweet_lemmatized'])\n",
    "lemm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words='english')\n",
    "tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_lemm = tfidf_vectorizer.fit_transform(df['tweet_lemmatized'])\n",
    "tfidf_lemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = lemm\n",
    "# splitting data into training test split\n",
    "xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(train, df_train['sentiment'], random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg = LogisticRegression()\n",
    "lreg.fit(xtrain_bow, ytrain) # training the model\n",
    "\n",
    "prediction = lreg.predict(xvalid_bow) # predicting on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(f1_score(yvalid, prediction, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(xtrain_bow, ytrain)\n",
    "predictions = naive_bayes.predict(xvalid_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(yvalid, predictions, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearSVC Algorithm\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(training_set)\n",
    "print(\"LinearSVC Algo Accuracy : \", (nltk.classify.accuracy(LinearSVC_classifier, testing_set))*100 , \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
